### Introduction

This notebook contains an example of a workflow for performing exploratory data analysis to investigate a dataset that will be used to train an object detection model. I use transfer learning and replace the classification head of `sd_resnet50_v1_fpn_640x640_coco17_tpu-8` model so that it can detect the new class of object defined in our dataset. I describe the model selected in great detail in the notebook. This notebook is part of a training exercise that explores real-world obstacles when dealing with data provided from scientists or other sources. 

In this case, our training data set contains histology images with annotations that label cells of interest. The original images are not publicly available so they had to be omitted from this notebook, however the code and descriptions offer a practical workflow with some example outputs. As you will see in the section "Summary of Data Quality" our training data is significantly flawed, which inhibits out ability to achieve a high level of model accuracy. From a visual inspection of the dataset, in many cases there are missing annotations for cells, which would significantly decrease training accuracy because the absence of annotations is random. An important part of model training is to ensure that high quality data is provided, and this notebook is a good example of the "garbage in, garbage out" paradigm popular in Data Science. In creating an enterprise solution, this notebook would prove that higher quality data is necessary and I would work with a scientist to obtain a better dataset before repeating training. 

